<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-09-09T10:55:08-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alfred Adjei-Darko</title><subtitle>Personal Website of Alfred Adjei-Darko</subtitle><entry><title type="html">Gender Pay Analysis</title><link href="http://localhost:4000/posts/2023-09-09-gender-pay-analysis" rel="alternate" type="text/html" title="Gender Pay Analysis" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/gender-pay-analysis</id><content type="html" xml:base="http://localhost:4000/posts/2023-09-09-gender-pay-analysis"><![CDATA[<p>https://drive.google.com/drive/u/0/folders/1kR_ceZhX7pyS2rXFPt1xm4awt9n1FdWE</p>

<p>https://www.glassdoor.com/research/gender-pay-gap
https://www.glassdoor.com/research/how-to-analyze-gender-pay-gap-employers-guide
https://www.glassdoor.com/research/glassdoor-pay-equity-analysis-2022</p>

<p>Sales Forecasting: https://github.com/chhaviarora95/salesforecasting/blob/master/Sales%20Forecasting.ipynb
Salary Predictions: https://github.com/chhaviarora95/Salary-Prediction-Portfolio/blob/master/Salary_PredictionNotebook.ipynb</p>]]></content><author><name></name></author><summary type="html"><![CDATA[https://drive.google.com/drive/u/0/folders/1kR_ceZhX7pyS2rXFPt1xm4awt9n1FdWE]]></summary></entry><entry><title type="html">The Normal Distribution and the 68-95-99.7 Rule</title><link href="http://localhost:4000/posts/2023-08-29-normal-68-95-99" rel="alternate" type="text/html" title="The Normal Distribution and the 68-95-99.7 Rule" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/normal-68-95-99</id><content type="html" xml:base="http://localhost:4000/posts/2023-08-29-normal-68-95-99"><![CDATA[<iframe width="720" height="360" src="https://www.youtube.com/embed/mtbJbDwqWLE" title="The Normal Distribution and the 68-95-99.7 Rule (5.2)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Receiving &amp;amp; Processing Feedback</title><link href="http://localhost:4000/posts/2023-09-01-feedback" rel="alternate" type="text/html" title="Receiving &amp;amp; Processing Feedback" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/feedback</id><content type="html" xml:base="http://localhost:4000/posts/2023-09-01-feedback"><![CDATA[<p>https://docs.google.com/document/d/1pepJosGjvCqj9IBBOUx9FKrzs_qQQxUlPxDOMW0Bbj4/edit?pli=1</p>]]></content><author><name></name></author><summary type="html"><![CDATA[https://docs.google.com/document/d/1pepJosGjvCqj9IBBOUx9FKrzs_qQQxUlPxDOMW0Bbj4/edit?pli=1]]></summary></entry><entry><title type="html">Standard Deviation</title><link href="http://localhost:4000/posts/2023-08-29-standard-deviation" rel="alternate" type="text/html" title="Standard Deviation" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/standard-deviation</id><content type="html" xml:base="http://localhost:4000/posts/2023-08-29-standard-deviation"><![CDATA[<iframe width="720" height="360" src="https://www.youtube.com/embed/esskJJF8pCc" title="Standard deviation (simply explained)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">A survey of Surveys I Like</title><link href="http://localhost:4000/posts/2023-09-01-surveys-i-like" rel="alternate" type="text/html" title="A survey of Surveys I Like" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/surveys-i-like</id><content type="html" xml:base="http://localhost:4000/posts/2023-09-01-surveys-i-like"><![CDATA[<p>https://docs.google.com/document/d/1DGLfjot51OGWLT9R19ldJ7P897CuLiOgAkeyuhVXsP8/edit</p>]]></content><author><name></name></author><summary type="html"><![CDATA[https://docs.google.com/document/d/1DGLfjot51OGWLT9R19ldJ7P897CuLiOgAkeyuhVXsP8/edit]]></summary></entry><entry><title type="html">PARA</title><link href="http://localhost:4000/posts/2023-08-29-para" rel="alternate" type="text/html" title="PARA" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/para</id><content type="html" xml:base="http://localhost:4000/posts/2023-08-29-para"><![CDATA[<p>According to Tiago Forte from <a href="https://bigthink.com/smart-skills/para-method-organize-digital-lives-4-simple-categories/">BigThink</a>,
PARA is a simple, comprehensive, yet flexible system for organizing any type of information across any digital platform.</p>

<h2 id="projects">Projects</h2>
<p>Projects you’re actively working on — short-term efforts (whether in your work or personal life) that you take on with a certain goal in mind. For example: complete webpage design; buy a new computer; write research report; renovate the bathroom; finish Spanish-language course; set up new living room furniture.</p>

<h2 id="responsibilities">Responsibilities</h2>
<p>Areas of responsibility — important parts of your work and life that require ongoing attention more broadly. These might include: Work responsibilities, such as marketing, human resources, product management, research and development, direct reports, or software development. Personal responsibilities such as health, finances, kids, writing, car, or home.</p>

<h2 id="resources">Resources</h2>
<p>Resources on a range of topics you’re interested in and learning about, such as: graphic design; organic gardening; web design; Japanese cuisine; photography; marketing assets.</p>

<h2 id="archives">Archives</h2>
<p>Anything from the previous three categories that is no longer active but you might want to save for future reference: projects you’ve completed or put on hold; areas that are no longer active or relevant; resources that you’re no longer interested in.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[According to Tiago Forte from BigThink, PARA is a simple, comprehensive, yet flexible system for organizing any type of information across any digital platform.]]></summary></entry><entry><title type="html">Diversity, Equity, and Inclusion</title><link href="http://localhost:4000/posts/2023-09-01-dei" rel="alternate" type="text/html" title="Diversity, Equity, and Inclusion" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/dei</id><content type="html" xml:base="http://localhost:4000/posts/2023-09-01-dei"><![CDATA[<p>https://docs.google.com/document/d/1yynjbFj7mGCQDtxgXNxkixuFmJDYN90BPicMAUdLpaw/edit</p>]]></content><author><name></name></author><summary type="html"><![CDATA[https://docs.google.com/document/d/1yynjbFj7mGCQDtxgXNxkixuFmJDYN90BPicMAUdLpaw/edit]]></summary></entry><entry><title type="html">Catalogue of Bias</title><link href="http://localhost:4000/posts/2023-08-29-catalogue-of-bias" rel="alternate" type="text/html" title="Catalogue of Bias" /><published>2023-08-29T08:14:53-04:00</published><updated>2023-08-29T08:14:53-04:00</updated><id>http://localhost:4000/posts/catalogue-of-bias</id><content type="html" xml:base="http://localhost:4000/posts/2023-08-29-catalogue-of-bias"><![CDATA[<ul>
  <li>https://catalogofbias.org/biases/</li>
  <li>https://catalogofbias.org/biases/availability-bias/</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[https://catalogofbias.org/biases/ https://catalogofbias.org/biases/availability-bias/]]></summary></entry><entry><title type="html">Ethics of Data and Analytics</title><link href="http://localhost:4000/posts/2023-06-2-ethics-of-data-and-analytics" rel="alternate" type="text/html" title="Ethics of Data and Analytics" /><published>2023-06-02T15:14:53-04:00</published><updated>2023-06-02T15:14:53-04:00</updated><id>http://localhost:4000/posts/ethics-of-data-and-analytics</id><content type="html" xml:base="http://localhost:4000/posts/2023-06-2-ethics-of-data-and-analytics"><![CDATA[<p>Joel Shapiro shared an insightful perspective on how <i>Advanced analytics and AI can easily lead to decisions that are considered “biased”</i>.
In a recent <a href="https://hbr.org/2023/05/when-to-give-employees-access-to-data-and-analytics#">HBR article</a> exploring the optimal time and degree to which data professionals and employers are to democratize data, he relates a cautionalry tale in the form of a case study featuring Goldman Sachs:</p>

<blockquote>
  <p>Goldman Sachs … was accused of discriminating by offering less credit on an Apple credit card to women than to men. In response, Goldman Sachs said it did not use gender in its model, only factors such as credit history and income. However, one could argue that credit history and income are correlated to gender and using those variables punishes women who tend to make less money on average and historically have had less opportunity to build credit. <mark>When using output that discriminates, decision-makers and data professionals alike need to understand how the data were generated and the interconnectedness of the data, as well as how to measure such things as differential treatment and much more</mark>.</p>
</blockquote>

<p>To mitigate the harms to minority groups, we musst also prioritize fairness, accountability, and transparency in the development of algorithms and AI systems. This includes involving diverse stakeholders in decision-making processes, regularly auditing algorithms for bias, and ensuring that individuals and communities have the right to access, control, and understand the data collected about them.</p>

<p style="text-align: center">***</p>

<p>Henry Kissinger, Google’s Eric Schmidt, and Daniel Huttenlocher further the subject of ethics in data and analytics – specifically, in A.I. – in their book “The Age of A.I.” In the book, when they explore the concept of <i>Dataset Bias</i>, they make the case that machine learning requires substantial amounts of data without which AI cannot learn good models. In instances where there is insufficient data recorded for minority groups like racial minorities, the AI ends up with results that are poor in accuracy. A good example of an instance where insufficient data can lead to suboptimal results can be  found in facial recognition systems. These systems have often been trained with disproportionately fewer pictures of people of color. When they have to perform the task of identifying black people, then, they tend to perform poorly.</p>

<p>There is also the matter of coverage. Training AI does not just require large amounts of data. The data needs to be varied. Training AI with vast amounts of similar data results in neural networks that are incorrectly certain of outcomes because they have never encountered the precipitating conditions before. Consider for example, the extraordinary situation of a deer leaping in front of a self-driving car. If the A.I. has not be trained on what to do in such an instance, it is left unspecified as to what action it is to take.</p>

<p>Human Bias can also Transfer into A.I. Systems. An A.I. reward function can reward a series of chess moves that the encoder subjectively favors.</p>

<p>Bias is not only limited to A.I. technology either. Consider the pulse oximeter, a tool used to measure oxygen saturation in the blood. This tool has been known to overestimate the oxygen saturation in dark skinned individuals because it or its designers assumed that the way light skin absorbs light was ‘normal.’</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Joel Shapiro shared an insightful perspective on how Advanced analytics and AI can easily lead to decisions that are considered “biased”. In a recent HBR article exploring the optimal time and degree to which data professionals and employers are to democratize data, he relates a cautionalry tale in the form of a case study featuring Goldman Sachs:]]></summary></entry><entry><title type="html">A Survey of Visualizations I Like</title><link href="http://localhost:4000/posts/2023-05-8-vizs-I-like" rel="alternate" type="text/html" title="A Survey of Visualizations I Like" /><published>2023-05-08T12:34:53-04:00</published><updated>2023-05-08T12:34:53-04:00</updated><id>http://localhost:4000/posts/vizs-I-like</id><content type="html" xml:base="http://localhost:4000/posts/2023-05-8-vizs-I-like"><![CDATA[<link rel="stylesheet" href="/assets/css/style.css" />

<p>Click on an image for an enlarged view and description</p>

<div class="image-container">
    <a href="#" class="image-link" data-description="What it is: The Article metrics widget displays article-level metrics, including views, citation counts from CrossRef, the Web of Science, and Scopus. It also displays the Altmetric Attention Score. &#10; &lt;br&gt;
                                                    Why I like it: ">
        <img src="/assets/images/blog/1.png" alt="Image 1" />
    </a>
    <a href="#" class="image-link" data-description="Image 2 description">
        <img src="/assets/images/portfolio/adp.png" alt="Image 2" />
    </a>
    <a href="#" class="image-link" data-description="Image 3 description">
        <img src="/assets/images/portfolio/mls1.png" alt="Image 3" />
    </a>
    <a href="#" class="image-link" data-description="Image 4 description">
        <img src="/assets/images/portfolio/adp.png" alt="Image 4" />
    </a>
    <a href="#" class="image-link" data-description="Image 1 description">
        <img src="/assets/images/portfolio/mls1.png" alt="Image 1" />
    </a>
    <a href="#" class="image-link" data-description="Image 2 description">
        <img src="/assets/images/portfolio/adp.png" alt="Image 2" />
    </a>
    <a href="#" class="image-link" data-description="Image 3 description">
        <img src="/assets/images/portfolio/mls1.png" alt="Image 3" />
    </a>
    <a href="#" class="image-link" data-description="Image 4 description">
        <img src="/assets/images/portfolio/adp.png" alt="Image 4" />
    </a>
    <!-- Add more image links here -->
</div>

<div class="popup">
    <div class="close">&times;</div>
    <img src="" alt="" />
    <p class="description"></p>
</div>
<script>
  const imageLinks = document.querySelectorAll('.image-link');
  const popup = document.querySelector('.popup');
  const popupClose = document.querySelector('.popup .close');
  const popupImage = document.querySelector('.popup img');
  const popupDescription = document.querySelector('.popup .description');
  imageLinks.forEach(link => {
      link.addEventListener('click', event => {
          event.preventDefault();
          const image = link.querySelector('img');
          const description = link.dataset.description;
          popupImage.src = image.src;
          popupImage.alt = image.alt;
        //   popupDescription.textContent = description;
        // Use innerHTML to respect HTML entities and tags
        // Be careful with this approach as it can be a vector for XSS if not properly sanitized
          popupDescription.innerHTML = description.replace(/&#10;/g, '<br>'); // replace newline entity with <br> tag
          popup.style.display = 'block';
      });
  });
  popupClose.addEventListener('click', () => {
      popup.style.display = 'none';
  });
</script>]]></content><author><name></name></author><summary type="html"><![CDATA[Click on an image for an enlarged view and description]]></summary></entry></feed>