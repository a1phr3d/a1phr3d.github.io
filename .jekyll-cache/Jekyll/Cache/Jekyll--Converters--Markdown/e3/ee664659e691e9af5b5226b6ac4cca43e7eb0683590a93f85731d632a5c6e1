I"œ<blockquote>
  <p>Goldman Sachs â€¦ was accused of discriminating by offering less credit on an Apple credit card to women than to men. In response, Goldman Sachs said it did not use gender in its model, only factors such as credit history and income. However, one could argue that credit history and income are correlated to gender and using those variables punishes women who tend to make less money on average and historically have had less opportunity to build credit. <mark>When using output that discriminates, decision-makers and data professionals alike need to understand how the data were generated and the interconnectedness of the data, as well as how to measure such things as differential treatment and much more</mark>. A company should never put its reputation on the line by having a citizen data scientist alone determine whether a model is biased.
Democratizing data has its merits, but it comes with challenges. Giving the keys to everyone doesnâ€™t make them an expert, and gathering the wrong insights can be catastrophic. New software tools can allow everyone to use data, but donâ€™t mistake that widespread access for genuine expertise.</p>
</blockquote>
:ET